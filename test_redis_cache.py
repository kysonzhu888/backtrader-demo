#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Redisç¼“å­˜åŠŸèƒ½æµ‹è¯•è„šæœ¬
"""

import sys
import os
import time
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from mini_stock.redis_cache_manager import RedisCacheManager

def test_redis_cache():
    """æµ‹è¯•Redisç¼“å­˜åŠŸèƒ½"""
    print("å¼€å§‹æµ‹è¯•Redisç¼“å­˜åŠŸèƒ½...")
    
    # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
    cache_manager = RedisCacheManager(host='localhost', port=6379, db=0)
    
    if not cache_manager.redis_client:
        print("âŒ Redisè¿æ¥å¤±è´¥ï¼Œè¯·ç¡®ä¿RedisæœåŠ¡æ­£åœ¨è¿è¡Œ")
        return False
    
    print("âœ… Redisè¿æ¥æˆåŠŸ")
    
    # æµ‹è¯•æ•°æ®
    test_stock_code = "000001.SZ"
    test_data = {
        "code": test_stock_code,
        "price": 12.34,
        "volume": 1000000,
        "change": 0.56,
        "change_pct": 4.76,
        "open": 11.80,
        "high": 12.50,
        "low": 11.75,
        "close": 12.34
    }
    
    # æµ‹è¯•1: ç¼“å­˜å•åªè‚¡ç¥¨æ•°æ®
    print("\n1. æµ‹è¯•ç¼“å­˜å•åªè‚¡ç¥¨æ•°æ®...")
    success = cache_manager.cache_stock_data(test_stock_code, test_data)
    if success:
        print("âœ… å•åªè‚¡ç¥¨æ•°æ®ç¼“å­˜æˆåŠŸ")
    else:
        print("âŒ å•åªè‚¡ç¥¨æ•°æ®ç¼“å­˜å¤±è´¥")
        return False
    
    # æµ‹è¯•2: è·å–æœ€æ–°æ•°æ®
    print("\n2. æµ‹è¯•è·å–æœ€æ–°æ•°æ®...")
    latest_data = cache_manager.get_latest_stock_data(test_stock_code)
    if latest_data:
        print(f"âœ… è·å–æœ€æ–°æ•°æ®æˆåŠŸ: {latest_data['price']}")
    else:
        print("âŒ è·å–æœ€æ–°æ•°æ®å¤±è´¥")
        return False
    
    # æµ‹è¯•3: è·å–å½“å¤©æ‰€æœ‰æ•°æ®
    print("\n3. æµ‹è¯•è·å–å½“å¤©æ‰€æœ‰æ•°æ®...")
    today_data = cache_manager.get_stock_data_today(test_stock_code)
    if today_data:
        print(f"âœ… è·å–å½“å¤©æ•°æ®æˆåŠŸï¼Œå…±{len(today_data)}æ¡è®°å½•")
        for i, data in enumerate(today_data[:3]):  # åªæ˜¾ç¤ºå‰3æ¡
            print(f"   è®°å½•{i+1}: ä»·æ ¼={data['price']}, æ—¶é—´={data['timestamp']}")
    else:
        print("âŒ è·å–å½“å¤©æ•°æ®å¤±è´¥")
        return False
    
    # æµ‹è¯•4: æ‰¹é‡ç¼“å­˜å¤šåªè‚¡ç¥¨
    print("\n4. æµ‹è¯•æ‰¹é‡ç¼“å­˜å¤šåªè‚¡ç¥¨...")
    batch_data = {
        "000002.SZ": {"code": "000002.SZ", "price": 15.67, "volume": 2000000},
        "000858.SZ": {"code": "000858.SZ", "price": 89.12, "volume": 1500000},
        "600036.SH": {"code": "600036.SH", "price": 45.23, "volume": 3000000}
    }
    success = cache_manager.cache_stocks_batch(batch_data)
    if success:
        print("âœ… æ‰¹é‡ç¼“å­˜æˆåŠŸ")
    else:
        print("âŒ æ‰¹é‡ç¼“å­˜å¤±è´¥")
        return False
    
    # æµ‹è¯•5: æ‰¹é‡è·å–æœ€æ–°æ•°æ®
    print("\n5. æµ‹è¯•æ‰¹é‡è·å–æœ€æ–°æ•°æ®...")
    codes = ["000001.SZ", "000002.SZ", "000858.SZ", "600036.SH"]
    latest_batch = cache_manager.get_multiple_latest_data(codes)
    if latest_batch:
        print(f"âœ… æ‰¹é‡è·å–æˆåŠŸï¼Œå…±{len(latest_batch)}åªè‚¡ç¥¨")
        for code, data in latest_batch.items():
            print(f"   {code}: ä»·æ ¼={data['price']}")
    else:
        print("âŒ æ‰¹é‡è·å–å¤±è´¥")
        return False
    
    # æµ‹è¯•6: ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
    print("\n6. æµ‹è¯•è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯...")
    stats = cache_manager.get_cache_stats()
    if stats:
        print("âœ… è·å–ç»Ÿè®¡ä¿¡æ¯æˆåŠŸ:")
        for key, value in stats.items():
            print(f"   {key}: {value}")
    else:
        print("âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥")
        return False
    
    # æµ‹è¯•7: ç­›é€‰ç»“æœç¼“å­˜
    print("\n7. æµ‹è¯•ç­›é€‰ç»“æœç¼“å­˜...")
    conditions = {
        "min_listed_days": 90,
        "exclude_st": True,
        "exclude_delisted": True
    }
    filter_result = [
        {"è‚¡ç¥¨ä»£ç ": "000001.SZ", "è‚¡ç¥¨åç§°": "å¹³å®‰é“¶è¡Œ", "å¸‚å€¼(äº¿)": 1500.5},
        {"è‚¡ç¥¨ä»£ç ": "000002.SZ", "è‚¡ç¥¨åç§°": "ä¸‡ç§‘A", "å¸‚å€¼(äº¿)": 1200.3}
    ]
    
    # ç¼“å­˜ç­›é€‰ç»“æœ
    success = cache_manager.cache_filter_result(conditions, filter_result, 300)
    if success:
        print("âœ… ç­›é€‰ç»“æœç¼“å­˜æˆåŠŸ")
    else:
        print("âŒ ç­›é€‰ç»“æœç¼“å­˜å¤±è´¥")
        return False
    
    # è·å–ç¼“å­˜çš„ç­›é€‰ç»“æœ
    cached_result = cache_manager.get_cached_filter_result(conditions)
    if cached_result:
        print(f"âœ… è·å–ç¼“å­˜ç­›é€‰ç»“æœæˆåŠŸï¼Œå…±{len(cached_result)}æ¡")
    else:
        print("âŒ è·å–ç¼“å­˜ç­›é€‰ç»“æœå¤±è´¥")
        return False
    
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Redisç¼“å­˜åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
    return True

def test_cache_cleanup():
    """æµ‹è¯•ç¼“å­˜æ¸…ç†åŠŸèƒ½"""
    print("\næµ‹è¯•ç¼“å­˜æ¸…ç†åŠŸèƒ½...")
    
    cache_manager = RedisCacheManager(host='localhost', port=6379, db=0)
    
    if not cache_manager.redis_client:
        print("âŒ Redisè¿æ¥å¤±è´¥")
        return False
    
    # æ¸…ç©ºå½“å¤©æ•°æ®
    success = cache_manager.clear_today_data()
    if success:
        print("âœ… å½“å¤©æ•°æ®æ¸…ç†æˆåŠŸ")
    else:
        print("âŒ å½“å¤©æ•°æ®æ¸…ç†å¤±è´¥")
        return False
    
    # æ£€æŸ¥æ¸…ç†åçš„ç»Ÿè®¡ä¿¡æ¯
    stats = cache_manager.get_cache_stats()
    if stats.get('total_records', 0) == 0:
        print("âœ… æ•°æ®æ¸…ç†éªŒè¯æˆåŠŸ")
    else:
        print(f"âŒ æ•°æ®æ¸…ç†éªŒè¯å¤±è´¥ï¼Œä»æœ‰{stats.get('total_records', 0)}æ¡è®°å½•")
        return False
    
    return True

if __name__ == "__main__":
    print("=" * 50)
    print("Redisç¼“å­˜åŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    # è¿è¡ŒåŸºæœ¬åŠŸèƒ½æµ‹è¯•
    if test_redis_cache():
        print("\n" + "=" * 50)
        # è¿è¡Œæ¸…ç†åŠŸèƒ½æµ‹è¯•
        test_cache_cleanup()
    else:
        print("\nâŒ åŸºæœ¬åŠŸèƒ½æµ‹è¯•å¤±è´¥ï¼Œè·³è¿‡æ¸…ç†æµ‹è¯•")
    
    print("\næµ‹è¯•å®Œæˆï¼") 